{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FurryTagger\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "%cd /\n",
    "!git clone --depth 1 https://huggingface.co/Thouph/eva02-vit-large-448-8046 /eva02-vit-large-448-8046\n",
    "%cd /eva02-vit-large-448-8046\n",
    "!git clone https://huggingface.co/datasets/k4d3/ayaya ./images\n",
    "!pip3 install -U timm\n",
    "\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "THRESHOLD = 0.3\n",
    "root_dir = r'./images'  # Change the root directory to the desired starting point\n",
    "\n",
    "model_path = r'./model.pth'\n",
    "\n",
    "model = torch.load(model_path, map_location=torch.device('cuda'))\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((448, 448)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[\n",
    "        0.48145466,\n",
    "        0.4578275,\n",
    "        0.40821073\n",
    "    ], std=[\n",
    "        0.26862954,\n",
    "        0.26130258,\n",
    "        0.27577711\n",
    "    ])\n",
    "])\n",
    "\n",
    "with open(\"tags_8041.json\", \"r\", encoding='utf8') as file:\n",
    "    tags = json.load(file)\n",
    "allowed_tags = sorted(tags)\n",
    "allowed_tags.insert(0, \"placeholder0\")\n",
    "allowed_tags.append(\"placeholder1\")\n",
    "allowed_tags.append(\"explicit\")\n",
    "allowed_tags.append(\"questionable\")\n",
    "allowed_tags.append(\"safe\")\n",
    "\n",
    "image_exts = ['.jpg', '.jpeg', '.png', '.gif']\n",
    "\n",
    "# Recurse into subdirectories\n",
    "image_files = [file for file in Path(root_dir).rglob('*') if file.suffix.lower() in image_exts]\n",
    "\n",
    "for image_path in image_files:\n",
    "    image_path_str = str(image_path)\n",
    "\n",
    "    img = Image.open(image_path_str).convert('RGB')\n",
    "    tensor = transform(img).unsqueeze(0).cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(tensor)\n",
    "\n",
    "    probabilities = torch.sigmoid(out[0])\n",
    "    indices = torch.where(probabilities > THRESHOLD)[0]\n",
    "    values = probabilities[indices]\n",
    "\n",
    "    sorted_indices = torch.argsort(values, descending=True)\n",
    "\n",
    "    tags_to_write = [allowed_tags[indices[i]].replace(\"_\", \" \") for i in sorted_indices if allowed_tags[indices[i]] not in (\"placeholder0\", \"placeholder1\")]\n",
    "\n",
    "    text_filename = image_path.stem + \".txt\"\n",
    "    text_path = image_path.parent / text_filename\n",
    "\n",
    "    with open(text_path, \"w\", encoding='utf8') as text_file:\n",
    "        text_file.write(\", \".join(tags_to_write))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r ./output.zip ./images/**/*.txt ./images/*.txt\n",
    "!mv ./output.zip /content/drive/MyDrive/output.zip"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
